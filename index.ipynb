{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio_file.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "hi\n",
      "hlw\n"
     ]
    },
    {
     "ename": "RequestError",
     "evalue": "recognition request failed: Bad Request",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\anuku\\miniconda3\\lib\\site-packages\\speech_recognition\\__init__.py:708\u001b[0m, in \u001b[0;36mRecognizer.recognize_google\u001b[1;34m(self, audio_data, key, language, pfilter, show_all, with_confidence)\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 708\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\anuku\\miniconda3\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anuku\\miniconda3\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\anuku\\miniconda3\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\anuku\\miniconda3\\lib\\urllib\\request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    560\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anuku\\miniconda3\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    493\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\anuku\\miniconda3\\lib\\urllib\\request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRequestError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhlw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Convert speech to text \u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Print the text \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anuku\\miniconda3\\lib\\site-packages\\speech_recognition\\__init__.py:710\u001b[0m, in \u001b[0;36mRecognizer.recognize_google\u001b[1;34m(self, audio_data, key, language, pfilter, show_all, with_confidence)\u001b[0m\n\u001b[0;32m    708\u001b[0m     response \u001b[38;5;241m=\u001b[39m urlopen(request, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperation_timeout)\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecognition request failed: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e\u001b[38;5;241m.\u001b[39mreason))\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecognition connection failed: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e\u001b[38;5;241m.\u001b[39mreason))\n",
      "\u001b[1;31mRequestError\u001b[0m: recognition request failed: Bad Request"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp \n",
    "import speech_recognition as sr \n",
    "\n",
    "# Load the video \n",
    "video = mp.VideoFileClip(\"C:\\\\Users\\\\anuku\\\\Downloads\\\\Aaj_Phir-Hate_Story_2-Full_FusionBD.Com.mp4\") \n",
    "\n",
    "# Extract the audio from the video \n",
    "audio_file = video.audio \n",
    "audio_file.write_audiofile(\"audio_file.wav\") \n",
    "\n",
    "# Initialize recognizer \n",
    "r = sr.Recognizer() \n",
    "print(\"hi\")\n",
    "# Load the audio file \n",
    "with sr.AudioFile(\"audio_file.wav\") as source: \n",
    "\tdata = r.record(source) \n",
    "\tprint(\"hlw\")\n",
    "\n",
    "# Convert speech to text \n",
    "text = r.recognize_google(data) \n",
    "print(\"why\")\n",
    "\n",
    "# Print the text \n",
    "print(\"\\nThe resultant text from video is: \\n\") \n",
    "print(text) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio_file.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Text from chunk 0:\n",
      "old we don't have a time of items to get you in might be fine if we have a little bit time so corporate events they sing a song different things\n",
      "Text from chunk 1:\n",
      "I don't see anyone in the comments and issue I don't see that the head of instruction of amount that's so I guess the next so looks like hey look like this look perfect tense\n",
      "Text from chunk 2:\n",
      "one person\n",
      "Text from chunk 3:\n",
      "I think we can we can help the Core prevents Team they do they do a lot of like a Catering and you know keep on tracking people down so I think if this team can take the mission to like try to help you you know\n",
      "Text from chunk 4:\n",
      "MCQ questions about what time frame are you looking at so in Siri this is this could be the same as the killer 14 launch where were saying basically since 13.0 what has you know what can I take improvements have been made the general manager\n",
      "Text from chunk 5:\n",
      "road map is completely public here is to but also because there are robotics and a new feature\n",
      "Text from chunk 6:\n",
      "individual little thing and then we just had 14 absolutely yeah was one of the you know excellent\n",
      "Text from chunk 7:\n",
      "integrations without any indication so we have a couple of things with vs code that could be notable by I can I show what I did for SC and just to get some general feedback if someone has been downloaded\n",
      "Text from chunk 8:\n",
      "you know forget myself for doing something for yourself in marketing some things there but actually when I look around this pretty much does the only way I could make\n",
      "Text from chunk 9:\n",
      "Afghanistan similar approach for monitor with incident management they were bunch of things that we released although the core of incident management was first\n",
      "Text from chunk 10:\n",
      "an an upward WhatsApp contributions which is also connected so that's right\n",
      "Text from chunk 11:\n",
      "I think that's what measuring excitement levels 1 2 and 3 is there I was I was looking at maybe Mau as a metric to perhaps measured by the customers have started using the interested in using that or not we probably may not have it for everything but at least some of it wherever we have it is probably something we can we can use but we of course level of water we want to call 1 2 8 3 1\n",
      "Text from chunk 12:\n",
      "approach or when there is a lot of demand something like that surely it's something shift in a lot of people are using it that may you that's another good measure I don't know that any one of those needs can be exclusive I think it's a better individual judgement college what is what is your feeling based on you know really it's ok\n",
      "Text from chunk 13:\n",
      "especially the case we have slim pickings alternative entries then we can stack ring so that's that's kind of also helpful there are so if we have three for all of these that I mean it looks like we're going to get there and that's going to be quite a lot of features so I like this baby you can only give about 11233 just like you more\n",
      "Text from chunk 14:\n",
      "Chief Justice of the Rough like pass and like a lot of things recently happened moving between dogs and spreadsheet in the spreadsheet the Ducks this you know is the idea that during the production\n",
      "Text from chunk 15:\n",
      "well that there are some level of like an announcement that we make cares about that announcement again really tough to do at your life because it's all been around for a while so this is this is our time to head to that area announcement of the event and maybe some things that have been around top 5 overall baby we can just you know\n",
      "Text from chunk 16:\n",
      "so baby we can do you like 5 minutes kind of like I'm taking would be a top 5 available list of you know\n",
      "Text from chunk 17:\n",
      "the proprietary scanning without making it sound like the scanning improvements because that sounds like they were good before yeah marriage\n",
      "Text from chunk 18:\n",
      "the PR team like target attention on the acquisition on the inauguration I just feel like it's kind of worn out now press on problem management and analysis\n",
      "Text from chunk 19:\n",
      "which between between the proprietorship involuntary Management which would you focus on numbers to management integration I think we have a lot of customers actually using that already\n",
      "Text from chunk 20:\n",
      "first rashi for education probably worth talking about Tuesday I think I want to try to understand\n",
      "Text from chunk 21:\n",
      "on this format\n",
      "Text from chunk 22:\n",
      "statue of carpet and you go like you go to the gym and need carbon all the children with sit on a square of carbon that was like you have been assembly so that's what we can add more interesting\n",
      "Text from chunk 23:\n",
      "I mean I am already at the features for CD configure as well as monitor getting it reviewed from pm my guess was on my understanding was that we wouldn't have the same set of competitors that we can compare two but the right competitors for that particular stage right so for example for for monitor we may not have like a GitHub or something like that we would have monitor based competitors that we understand that entire list of competitors and partners for every single stage I thought we were going to be using those competitors to compare against so I just wanted your input on WhatsApp some of you have compared with the five competitors already listed over there\n",
      "Text from chunk 24:\n",
      "they may not be relevant for example cloudbees may not be relevant for monitor stage at all so that's what I want to check I mean if the comparator does not apply the particular station beyond spreadsheet sorry saying that you see compilers on that for a stage where they don't apply a different set of competitors that we need to include which I think we already identify top three competitors for every stage program\n",
      "Text from chunk 25:\n",
      "one competitors and if they are not if they don't are not applicable then we don't have to fill out anything for that we need to add a line item as well because I think that's Here Without features\n",
      "Text from chunk 26:\n",
      "exactly like market line so write your words like this is what I am shopping for this solution\n",
      "Text from chunk 27:\n",
      "at last scene and other lessons we still need to figure something out there are you doing\n",
      "Text from chunk 28:\n",
      "best description this is why I send everything Google photograph\n",
      "Text from chunk 29:\n",
      "players along the way stages available\n",
      "Text from chunk 30:\n",
      "configure in Bangladesh scripted as it could be by the place where one thing right time to do this right manager be updated with the underlying data remains the same rate in presentation\n",
      "Text from chunk 31:\n",
      "best of the 15 features and that's where you can describe what the hell is what the hacker manager coming in anything about 1550 features\n",
      "Text from chunk 32:\n",
      "it's not obviously negative comparison more than a competitive because of that because there is no you know 30% in the world largest population distribution\n",
      "Text from chunk 33:\n",
      "call time but I don't want to share one thing that can I came in like basically Friday for me so this is another thing about these things here so this was the father that I got like from road map\n",
      "Text from chunk 34:\n",
      "relation we are transparent and a single source of truth possibilities are starting this was really pretty and catchy I really like it I really liked what's the other than that I like the other phone does all in one for everyone so I just I don't know I like you words and control of yourself factory\n",
      "Text from chunk 35:\n",
      "next one that doesn't have anything under security so when I first got this it didn't have this and I didn't have anything and security mine this is I just put yourself\n",
      "Text from chunk 36:\n",
      "and then actually let's start here this one I could take white because I like things to have priority in in their own right so this is maybe like super new launched element but I hate it if it's like a single source of truth that's like a noun phrase and then control that like is\n",
      "Text from chunk 37:\n",
      "I store and control your software and its syllabus\n",
      "Text from chunk 38:\n",
      "product 75 manufacture I like this one better\n",
      "Text from chunk 39:\n",
      "I like you may face with confidence better than increase speed in stay on track I was thinking of like you know if you are like if you are in a race car I like you go like super super fast like let's say you're in the bike race right and you going so fast and somebody who's out of the sign and like after the bike race classes you can keep going dangerous\n",
      "Text from chunk 40:\n",
      "I think between these two I like my Facebook confidence but I don't like that don't have fairly so that's why I think confidence statement of\n",
      "Google Speech Recognition could not understand the audio\n",
      "Text from chunk 42:\n",
      "Lakshmi ko WhatsApp status and I think this is due with another day so any additional parts\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Step 1: Extract audio from video\n",
    "video = mp.VideoFileClip(\"C:\\\\Users\\\\anuku\\\\Downloads\\\\Product Marketing Meeting (weekly) 2021-06-28.mp4\")\n",
    "audio_file = video.audio\n",
    "audio_file.write_audiofile(\"audio_file.wav\")\n",
    "\n",
    "# Step 2: Split audio into smaller chunks\n",
    "audio = AudioSegment.from_file(\"audio_file.wav\")\n",
    "chunk_length_ms = 60000  # 60 seconds\n",
    "chunks = make_chunks(audio, chunk_length_ms)\n",
    "\n",
    "# Step 3: Export chunks to separate files\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_name = f\"chunk{i}.wav\"\n",
    "    chunk.export(chunk_name, format=\"wav\")\n",
    "\n",
    "# Step 4: Initialize recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Step 5: Process each chunk\n",
    "for i in range(len(chunks)):\n",
    "    chunk_name = f\"chunk{i}.wav\"\n",
    "    with sr.AudioFile(chunk_name) as source:\n",
    "        data = r.record(source)\n",
    "        try:\n",
    "            text = r.recognize_google(data)\n",
    "            print(f\"Text from chunk {i}:\")\n",
    "            print(text)\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Google Speech Recognition could not understand the audio\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
